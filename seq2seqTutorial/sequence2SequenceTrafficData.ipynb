{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepData(filepath):\n",
    "    data = np.load(filepath)\n",
    "    xs = data['x'][:,:,:,0]\n",
    "    ys = data['y'][:,:,:,0]\n",
    "    xExamples = xs.reshape((data['x'].shape[0], data['x'].shape[1], -1))\n",
    "    yExamples = ys.reshape((data['y'].shape[0], data['y'].shape[1], -1))\n",
    "    return xExamples, yExamples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trafficX, trafficY = prepData(\"../DCRNN/data/train.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trafficValX, trafficValY = prepData(\"../DCRNN/data/val.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = trafficX.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers=1):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.gru=nn.GRU(input_size, hidden_size, num_layers=num_layers)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        #print(\"encoder input \", input)\n",
    "        input = input.view(1,1,-1).float()\n",
    "        output, hidden = self.gru(input, hidden)\n",
    "        #print(\"encoder output \", output)\n",
    "        return output, hidden\n",
    "    \n",
    "    def initHidden(self):\n",
    "        return torch.zeros(self.num_layers,1,self.hidden_size, device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, num_layers=1):\n",
    "        input_size = output_size\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.gru = nn.GRU(input_size, hidden_size, num_layers=num_layers)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "        self.num_layers = num_layers\n",
    "    def forward(self, input, hidden):\n",
    "        #print(\"decoder input: \", input)\n",
    "        input = input.view(1,1,-1).float()\n",
    "        output, hidden = self.gru(input, hidden)\n",
    "        #print(\"decoder outFC input\", output)\n",
    "        outRes = self.out(output)\n",
    "        #print(\"decoder outFC output\", outRes)\n",
    "        #output = self.softmax(outRes)\n",
    "        #print(\"decoder softmax output: \", output)\n",
    "        #return output, hidden\n",
    "        \n",
    "        return outRes, hidden\n",
    "    \n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1,1,self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = 1\n",
    "NULLCHAR = 0\n",
    "def train(input_tensor, target_tensor, encoder, decoder,\n",
    "          encoder_optimizer, decoder_optimizer, criterion,\n",
    "          max_length = MAX_LENGTH):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_tensor.size(0) # should be 12\n",
    "    target_length = target_tensor.size(0) # should be 12\n",
    "    \n",
    "    encoder_outputs = torch.zeros(max_length, \n",
    "                                  encoder.hidden_size, device=device)\n",
    "    loss = 0\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(\n",
    "            input_tensor[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0, 0]\n",
    "    \n",
    "    #first input to decoder is a null character (0)\n",
    "    #decoder_input = torch.tensor([[target_tensor[0]]], device=device)\n",
    "    \n",
    "    #initialize decoder hidden state to last encoder hidden state\n",
    "    decoder_hidden = encoder_hidden\n",
    "    decoder_input = torch.tensor([np.zeros(target_tensor.size()[-1])], device=device)\n",
    "    \n",
    "    use_teacher_forcing = True if random.random() <teacher_forcing_ratio else False\n",
    "    if use_teacher_forcing:\n",
    "        #feed the target as the next input\n",
    "        for di in range(target_length):\n",
    "            #decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "            #print(decoder_output, target_tensor[di])\n",
    "            \n",
    "            if criterion[1] == \"MSE\":\n",
    "                loss += torch.sqrt(criterion[0](decoder_output.squeeze(), target_tensor[di].squeeze().float()))\n",
    "            elif criterion[1] == \"Mean Absolute Error\":\n",
    "                loss += criterion[0](decoder_output.squeeze(), target_tensor[di].squeeze().float())\n",
    "            else:\n",
    "                assert 0, \"Cannot match loss\"\n",
    "            decoder_input = target_tensor[di]  # Teacher forcing\n",
    "    \n",
    "    else:\n",
    "        #use own prediction as the next input\n",
    "        for di in range(target_length):\n",
    "            #decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "            #topv, topi = decoder_output.topk(1)\n",
    "            \n",
    "            # detach from history as input\n",
    "            #decoder_input = topi.squeeze().detach()\n",
    "            decoder_input = decoder_output.squeeze().detach()\n",
    "            if criterion[1] == \"MSE\":\n",
    "                loss += torch.sqrt(criterion(decoder_output.squeeze(), target_tensor[di].squeeze().float()))\n",
    "            elif criterion[1] == \"Mean Absolute Error\":\n",
    "                loss += criterion(decoder_output.squeeze(), target_tensor[di].squeeze().float())\n",
    "            else:\n",
    "                assert 0, \"Cannot match loss\"\n",
    "            if decoder_input.item() == NULLCHAR:\n",
    "                break\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainIters(encoder, decoder, xMatrix, yMatrix, n_iters, model_description, xVal, yVal, print_every=1000, plot_every=100, learning_rate=0.01):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    validationLosses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    #criterion = (nn.MSELoss(),\"MSE\")\n",
    "    criterion = (nn.L1Loss(size_average=True), \"Mean Absolute Error\")\n",
    "    #valLoss = (nn.MSELoss(), \"MSE\")\n",
    "    valLoss = (nn.L1Loss(size_average=True), \"Mean Absolute Error\")\n",
    "    for iter in range(1, n_iters+1):\n",
    "        choice = np.random.randint(0, xMatrix.shape[0])\n",
    "        input_tensor = torch.FloatTensor(xMatrix[choice], device=device)\n",
    "        target_tensor = torch.FloatTensor(yMatrix[choice], device=device)\n",
    "        loss = train(input_tensor, target_tensor, encoder,\n",
    "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "        \n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "            # Get validation loss\n",
    "            validationLosses.append(validate(encoder, decoder, xVal, yVal, valLoss[0]))\n",
    "    showPlot(validationLosses, plot_every, model_description, criterion[1], training=False)\n",
    "    showPlot(plot_losses, plot_every, model_description, valLoss[1], training=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def showPlot(points, plot_every, model_description, lossDescription, training=True):\n",
    "    plt.rcParams.update({'font.size': 8})\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    #loc = ticker.MultipleLocator(base=0.2)\n",
    "    #ax.yaxis.set_major_locator(loc)\n",
    "    \n",
    "    plt.xlabel(\"iteration\")\n",
    "    plt.ylabel(lossDescription)\n",
    "    plt.plot(np.arange(len(points))*plot_every,points)\n",
    "    plt.grid()\n",
    "    plt.title(\"{} {} - {}\".format(\"training\" if training else \"Validation\", lossDescription, model_description))\n",
    "    filestring = \"./figs/{}_loss_plot_0.png\".format(\"training\" if training else \"Validation\")\n",
    "    while(os.path.isfile(filestring)):\n",
    "        filestring = filestring[:-5] + str(int(filestring[-5]) + 1) + \".png\"\n",
    "    plt.savefig(filestring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, inputSequence, max_length=MAX_LENGTH):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = inputSequence\n",
    "        input_length = input_tensor.size()[0] # should be 12 for traffic data 1 hr.\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "        \n",
    "        encoder_outputs = torch.zeros(\n",
    "            max_length,encoder.hidden_size, device=device)\n",
    "        \n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei],encoder_hidden)\n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "        \n",
    "        decoder_input = torch.tensor([np.zeros(input_tensor.size()[-1])], device=device)\n",
    "        \n",
    "        decoder_hidden = encoder_hidden\n",
    "        \n",
    "        nextSequence = []\n",
    "        #decoder_attention = torch.zeros(max_length, max_length)\n",
    "        \n",
    "        for di in range(max_length):\n",
    "            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "            \n",
    "            #decoder_attentions[di] = decoder_attention.data\n",
    "            #topv, topi = decoder_output.data.topk(1)\n",
    "#             if topi.item() == NULLCHAR:\n",
    "#                 nextSequence.append('XX')\n",
    "#                 break\n",
    "#             else:\n",
    "#                 nextSequence.append(topi.item())\n",
    "            nextSequence.append(decoder_output.data.squeeze().detach())\n",
    "            \n",
    "            decoder_input = decoder_output.data.squeeze().detach()\n",
    "        return nextSequence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateRandomly(encoder, decoder, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(tensorPairs)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        nextSequence = evaluate(encoder, decoder, pair[0])\n",
    "        outputSequence = ' '.join(nextSequence)\n",
    "        print('<', outputSequence)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(encoder, decoder, xMatrix, yMatrix, lossFn, n_vals=100):\n",
    "    loss = 0.0\n",
    "    for i in range(n_vals):\n",
    "        choice = np.random.randint(0, xMatrix.shape[0])\n",
    "        input_tensor = torch.FloatTensor(xMatrix[choice], device=device)\n",
    "        target_tensor = torch.FloatTensor(yMatrix[choice], device=device)\n",
    "        nextSequence = evaluate(encoder, decoder, input_tensor)\n",
    "        l = 0.0\n",
    "        for ps, ts in zip(nextSequence, target_tensor):\n",
    "            l += lossFn(ps, ts)\n",
    "        loss += l / len(nextSequence)\n",
    "    return loss / n_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danielzeiberg/miniconda3/lib/python3.6/site-packages/torch/nn/functional.py:52: UserWarning: size_average and reduce args will be deprecated, please use reduction='elementwise_mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 6s (- 2m 2s) (100 5%) 51.1468\n",
      "0m 13s (- 2m 1s) (200 10%) 39.8079\n",
      "0m 20s (- 1m 57s) (300 15%) 28.6940\n",
      "0m 27s (- 1m 51s) (400 20%) 19.5892\n",
      "0m 34s (- 1m 44s) (500 25%) 11.8336\n",
      "0m 41s (- 1m 37s) (600 30%) 8.3118\n",
      "0m 49s (- 1m 31s) (700 35%) 7.6935\n",
      "0m 56s (- 1m 25s) (800 40%) 7.6266\n",
      "1m 4s (- 1m 18s) (900 45%) 7.3595\n",
      "1m 11s (- 1m 11s) (1000 50%) 6.9032\n",
      "1m 18s (- 1m 4s) (1100 55%) 7.0101\n",
      "1m 26s (- 0m 57s) (1200 60%) 7.4244\n",
      "1m 33s (- 0m 50s) (1300 65%) 6.7797\n",
      "1m 40s (- 0m 43s) (1400 70%) 7.8439\n",
      "1m 47s (- 0m 35s) (1500 75%) 7.2518\n",
      "1m 55s (- 0m 28s) (1600 80%) 7.4844\n",
      "2m 2s (- 0m 21s) (1700 85%) 7.3034\n",
      "2m 9s (- 0m 14s) (1800 90%) 6.9842\n",
      "2m 17s (- 0m 7s) (1900 95%) 6.9402\n",
      "2m 24s (- 0m 0s) (2000 100%) 7.7803\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 256\n",
    "input_size = trafficX.shape[2]\n",
    "output_size = trafficY.shape[2]\n",
    "num_layers = 2\n",
    "modelDescription = \"RNN with GRU, {} unit hidden state, {} layer GRU\".format(hidden_size, num_layers) \n",
    "N_iters = 2000 #N_iters = trafficX.shape[0]\n",
    "encoder1 = EncoderRNN(input_size, hidden_size, num_layers).to(device)\n",
    "decoder1 = DecoderRNN(hidden_size, output_size, num_layers).to(device)\n",
    "trainIters(encoder1, decoder1, trafficX, trafficY, N_iters, modelDescription, trafficValX, trafficValY, print_every=100, plot_every=N_iters/100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "trafficData = np.load(\"../DCRNN/data/train.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['x', 'y', 'x_offsets', 'y_offsets']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trafficData.files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-11],\n",
       "       [-10],\n",
       "       [ -9],\n",
       "       [ -8],\n",
       "       [ -7],\n",
       "       [ -6],\n",
       "       [ -5],\n",
       "       [ -4],\n",
       "       [ -3],\n",
       "       [ -2],\n",
       "       [ -1],\n",
       "       [  0]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trafficData[\"x_offsets\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23974, 12, 207, 2)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trafficData['x'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danielzeiberg/miniconda3/lib/python3.6/site-packages/torch/nn/functional.py:52: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(6.)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = nn.L1Loss(size_average=False)\n",
    "t1 = torch.FloatTensor([[1,2,3], [4,5,6]])\n",
    "t2 = torch.FloatTensor([[2,3,4],[5,6,7]]) \n",
    "l(t1,t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(8.7823)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate(encoder1, decoder1, trafficValX, trafficValY, nn.L1Loss(), n_vals=trafficValX.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
